<!DOCTYPE HTML>
<html><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras</title>

<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" type="text/css" href="https://huajianup.github.io/assets/css/main.css">

<!--<link rel="stylesheet" type="text/css" href="../../assets/css/main.css">-->


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-178921838-1', 'auto');
	ga('send', 'pageview');
}
</script>

<body class="w3-content" style="max-width:1000px">

	<div class="w3-container w3-card w3-padding-large" >
		<div style="margin-top:9%">
			<h1 class="w3-center w3-margin-top" style="font-size: 45px;"  id="photo-slam"><b>Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras</b></h1>
			<br>
			<p><div class="w3-center" style="margin-left: 8px">
				<em><a href="https://huajianup.github.io" style="border-bottom: 1px dotted black;">Huajian Huang<sup>1</sup></a></em>, Longwei Li<sup>2</sup>, Hui Cheng<sup>2</sup>
				and 
				<em><a href="http://www.saikit.org" style="border-bottom: 1px dotted black;">Sai-Kit Yeung<sup>1</sup></a></em>
			</div></p>
			
			<p><div class="w3-center" style="margin-left: 4px">
				The Hong Kong University of Science and Technology<sup>1</sup>, Sun Yat-Sen University<sup>2</sup>
			</div></p>

			<div  class="w3-center"> Computer Vision and Pattern Recognition Conference (CVPR), 2024.
				</div>

			<br>
			<div class="link w3-center">
	            <a class="btn btn-primary outline" href="https://arxiv.org/abs/2311.16728" target="_blank"><i class="fa fa-file-pdf-o" style="margin-right: 5px"></i>Paper</a>
	        </div>
	    </div>

		<div class="w3-container w3-padding-large" style="margin-top:4%; margin-left:2%" >
			<img style="width:100% ;margin-top: auto"; src="../../thumbnails/Photo-SLAM_v2.gif" ></img>

		    <div class="w3-container w3-padding-small plate" id="abstract">
		    	<h2 id="abstract">Abstract</h2>
		    </div>
		    <p style="font-size: 18px;text-align: justify; "> The integration of neural rendering and the SLAM system recently showed promising results in joint 
				localization and photorealistic view reconstruction. However, existing methods, fully relying on implicit representations, are so resource-hungry 
				that they cannot run on portable devices, which deviates from the original intention of SLAM. In this paper, we present Photo-SLAM, a novel SLAM 
				framework with a hyper primitives map. Specifically, we simultaneously exploit explicit geometric features for localization and learn implicit 
				photometric features to represent the texture information of the observed environment. In addition to actively densifying hyper primitives based 
				on geometric features, we further introduce a Gaussian-Pyramid-based training method to progressively learn multi-level features, enhancing 
				photorealistic mapping performance. The extensive experiments with monocular, stereo, and RGB-D datasets prove that our proposed system 
				Photo-SLAM significantly outperforms current state-of-the-art SLAM systems for online photorealistic mapping, e.g., PSNR is 30\% higher and 
				rendering speed is hundreds of times faster in the Replica dataset. Moreover, the Photo-SLAM can run at real-time speed using an embedded platform 
				such as Jetson AGX Orin, showing the potential of robotics applications.<br/>
		    </p>
		</div>
		
		<div class="w3-container w3-padding-large" style="margin-top:4%; margin-left:2%" >
		    <div class="w3-container w3-padding-small plate" id="hiw">
		    	<h2 id="hiw">How it works</h2>
		    </div>
			<!--which capitalizes on explicit geometric feature points for accurate and efficient localization 
				while leveraging implicit representations to capture and model the texture information.-->
		    <p style="font-size: 18px;text-align: justify; "> 
				1. Introduce the concept of hyper primitives map. 
				<details>
					<summary>Details</summary>
					Hyper primitives are defined as a set of point clouds associated with ORB features, rotation, scaling, ensity, 
					and spherical harmonic (SH) coefficients. The hyper primitives map allows the system to efficiently optimize 
					tracking using a factor graph solver and learn the corresponding mapping by backpropagating the loss between
					the original images and rendering images.
					<img style="width:100% ;margin-top: auto"; src="img/overview.jpg" ></img> 
				  </details>
				<br/>
				2. Geometry-based densification
				<details>
					<summary>Details</summary>
					We argue that 2D geometric feature points spatially distributed in the frames essentially represent the region
					with a complex texture that requires more hyper primitives. However, less than 30% of 2D geometric feature points 
					of frames are active and have corresponding 3D points, especially for non-RGB-D scenarios. Therefore, we actively 
					create additional temporary hyper primitives based on the inactive 2D feature points.
					<img style="width:100% ;margin-top: auto"; src="img/Geo.jpg" ></img> 
				  </details><br/>
				3. Gaussian-pyramid-based learning, a new progressive training method.
				<details>
					<summary>Details</summary>
					Progressive training is a widely used technology in neural rendering to accelerate the optimization process. 
					Some methods have been proposed to reduce training time while achieving better rendering quality. 
					To enhance performance with efficient multi-level features learning online, we propose Gaussian-pyramid-based learning.
					At the beginning training step, the hyper primitives are supervised by the highest level of the pyramid, i.e. level n. 
					As training iteration increases, we not only densify hyper primitives but also reduce the pyramid level and obtain a 
					new ground truth until reaching the bottom of the Gaussian pyramid.
					<img style="width:100% ;margin-top: auto"; src="img/GP_learning.jpg" ></img> 
				  </details><br/>
		    </p>
		</div>

		<div class="w3-container w3-padding-large" style="margin-top:4%; margin-left:2%" >
		    <div class="w3-container w3-padding-small plate" id="result">
		    	<h2 id="result">Results</h2>
		    </div>
		    <p style="font-size: 18px;text-align: justify; "> <br/>
		    </p>
		</div>


		<div class="w3-container w3-padding-large" style="margin-top:10px; margin-left:2%;">
			<h3 id="citation">Citation</h3>
			<pre style="margin:0; background: #e8e8e7"><code><span>@inproceedings</span>{hhuang2024photoslam,
			title = {Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras},
			author = {Huang, Huajian and Li, Longwei and Cheng Hui and Yeung, Sai-Kit},
				booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
				year = {2024},
			}</code></pre> 
		</div>
	

	</div>
</body>
</html>
