<!DOCTYPE HTML>
<html><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras</title>

<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" type="text/css" href="https://huajianup.github.io/assets/css/main.css">

<!--<link rel="stylesheet" type="text/css" href="../../assets/css/main.css">-->


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-178921838-1', 'auto');
	ga('send', 'pageview');
}
</script>

<body class="w3-content" style="max-width:1000px">

	<div class="w3-container w3-card w3-padding-large" >
		<div style="margin-top:9%">
			<h1 class="w3-center w3-margin-top" style="font-size: 45px;"  id="photo-slam"><b>Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras</b></h1>
			<br>
			<p><div class="w3-center" style="margin-left: 8px">
				<em><a href="https://huajianup.github.io" style="border-bottom: 1px dotted black;">Huajian Huang<sup>1</sup></a></em>, Longwei Li<sup>2</sup>, Hui Cheng<sup>2</sup>
				and 
				<em><a href="http://www.saikit.org" style="border-bottom: 1px dotted black;">Sai-Kit Yeung<sup>1</sup></a></em>
			</div></p>
			
			<p><div class="w3-center" style="margin-left: 4px">
				The Hong Kong University of Science and Technology<sup>1</sup>, Sun Yat-Sen University<sup>2</sup>
			</div></p>

			<div  class="w3-center"> Computer Vision and Pattern Recognition Conference (CVPR), 2024.
				</div>

			<br>
			<div class="link w3-center">
	            <a class="btn btn-primary outline" href="https://arxiv.org/abs/2311.16728" target="_blank"><i class="fa fa-file-pdf-o" style="margin-right: 5px"></i>Paper</a>
	        </div>
	    </div>

		<div class="w3-container w3-padding-large" style="margin-top:4%; margin-left:2%" >
			<img style="width:100% ;margin-top: auto"; src="../../thumbnails/Photo-SLAM_v2.gif" ></img>
		    <div class="w3-container w3-padding-small plate" id="abstract">
		    	<h2 id="abstract">Abstract</h2>
		    </div>
		    <p style="font-size: 18px;text-align: justify; "> The integration of neural rendering and the SLAM system recently showed promising results in joint 
				localization and photorealistic view reconstruction. However, existing methods, fully relying on implicit representations, are so resource-hungry 
				that they cannot run on portable devices, which deviates from the original intention of SLAM. In this paper, we present Photo-SLAM, a novel SLAM 
				framework with a hyper primitives map. Specifically, we simultaneously exploit explicit geometric features for localization and learn implicit 
				photometric features to represent the texture information of the observed environment. In addition to actively densifying hyper primitives based 
				on geometric features, we further introduce a Gaussian-Pyramid-based training method to progressively learn multi-level features, enhancing 
				photorealistic mapping performance. The extensive experiments with monocular, stereo, and RGB-D datasets prove that our proposed system 
				Photo-SLAM significantly outperforms current state-of-the-art SLAM systems for online photorealistic mapping, e.g., PSNR is 30\% higher and 
				rendering speed is hundreds of times faster in the Replica dataset. Moreover, the Photo-SLAM can run at real-time speed using an embedded platform 
				such as Jetson AGX Orin, showing the potential of robotics applications.<br/>
		    </p>
		</div>
		
		<div class="w3-container w3-padding-large" style="margin-top:4%; margin-left:2%" >
		    <div class="w3-container w3-padding-small plate" id="hiw">
		    	<h2 id="hiw">How it works</h2>
		    </div>
			<!--which capitalizes on explicit geometric feature points for accurate and efficient localization 
				while leveraging implicit representations to capture and model the texture information.-->
		    <p style="font-size: 18px;text-align: justify; "> 
				1. maintain a map with hyper primitives online<br/>
				2. geometry-based densification<br/>
				3. Gaussian-pyramid-based learning<br/>
				<img style="width:100% ;margin-top: auto"; src="img/overview.jpg" ></img> 
				<img style="width:100% ;margin-top: auto"; src="img/Geo.jpg" ></img> 
				<img style="width:100% ;margin-top: auto"; src="img/GP_learning.jpg" ></img> 
		    </p>
		</div>

		<div class="w3-container w3-padding-large" style="margin-top:4%; margin-left:2%" >
		    <div class="w3-container w3-padding-small plate" id="result">
		    	<h2 id="result">Results</h2>
		    </div>
		    <p style="font-size: 18px;text-align: justify; "> <br/>
		    </p>
		</div>


		<div class="w3-container w3-padding-large" style="margin-top:10px; margin-left:2%;">
			<h3 id="citation">Citation</h3>
			<pre style="margin:0; background: #e8e8e7"><code><span>@inproceedings</span>{hhuang2024photoslam,
			title = {Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras},
			author = {Huang, Huajian and Li, Longwei and Cheng Hui and Yeung, Sai-Kit},
				booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
				year = {2024},
			}</code></pre> 
		</div>
	

	</div>
</body>
</html>
